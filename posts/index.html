<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Posts | wuyangzz</title>
<meta name="keywords" content="">
<meta name="description" content="Posts - wuyangzz">
<meta name="author" content="wuyangzz">
<link rel="canonical" href="https://wuyangzz.github.io/posts/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css" integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://wuyangzz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://wuyangzz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://wuyangzz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://wuyangzz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://wuyangzz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://wuyangzz.github.io/posts/index.xml">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Posts" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://wuyangzz.github.io/posts/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Posts"/>
<meta name="twitter:description" content=""/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://wuyangzz.github.io/posts/"
    }
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://wuyangzz.github.io/" accesskey="h" title="wuyangzz (Alt + H)">wuyangzz</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wuyangzz.github.io/posts/" title="博客">
                    <span class="active">博客</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/about/" title="关于我">
                    <span>关于我</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header">
  <h1>
    Posts
  </h1>
</header>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>常用工具推荐
    </h2>
  </header>
  <div class="entry-content">
    <p>提高效率的工具 1.Github Colopit\Tabnine(阿里) 强烈推荐！！！！！ Github Copilot是一个VS Code扩展，它可以自动完成你的代码，也可以通过看到你的注释和函数名来合成代码。这是用相同的模型构建的，并在数十亿的公共代码上进行了训练。
官网：https://github.com/features/copilot 介绍: GitHub Copilot 是一个 AI 对编程工具，可在您编写代码时提供自动完成样式的建议。 您可以通过开始编写要使用的代码，或编写描述您希望代码执行的操作的自然语言注释，以接收来自 GitHub Copilot 的建议。 GitHub Copilot 分析您正在编辑的文件中的上下文以及相关文件，并从文本编辑器中提供建议。 GitHub Copilot 经过优化，可帮助您编写 Python、JavaScript、TypeScript、Ruby、Go、C# 或 C&#43;&#43;。 您还可以使用 GitHub Copilot 以其他语言和各种框架生成建议。 GitHub Copilot 由 OpenAI Codex 提供支持，OpenAI Codex 是由 OpenAI 创建的新 AI 系统。 GitHub Copilot 可作为 IDE 的 Visual Studio Code、Visual Studio、Neovim 和 JetBrains 套件的扩展。
Visual Studio Code插件： https://docs.github.com/cn/copilot/getting-started-with-github-copilot/getting-started-with-github-copilot-in-visual-studio-code
 在Visual Studio Code Marketplace中，转到GitHub Copilot扩展页面，然后单击“安装”。   如果以前没有在GitHub帐户中授权Visual Studio代码，则会提示在Visual Studio Code中登录GitHub。如果以前在GitHub上为您的帐户授权了Visual Studio代码，则将自动授权GitHub Copilot。  JetBrains IDE插件： https://docs....</p>
  </div>
  <footer class="entry-footer"><span title='2022-08-29 10:40:49 +0800 CST'>August 29, 2022</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to 常用工具推荐" href="https://wuyangzz.github.io/2022/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Resume
    </h2>
  </header>
  <div class="entry-content">
    <p>吴洋 · 03/1999 · 13540430898 · wylmq911@gmail.com · WuYangzz · My Blog
项目与研究经历   成都试金石软件开发有限责任公司，Java 开发实习 崇州市人民医院预约展示系统，2022.07~至今
 主要使用技术：Spring Boot、SQL Server、MyBatis、Redis、WebSocket  实现门诊、医技的诊室小屏、签到机、科室大屏的展示及其后台管理系统。负责医院、科室、药品、医生坐班四个模块后端开发，并使用 WebSocket 实现对多终端页面的展示控制，加入 Redis 缓存提高系统性能。
  成都主导科技有限责任公司，算法实习 图像增强算法研究，2022.05~2022.07
提出一种仅利用三个单通道卷积便能实现灰度图低光增强模型，具有极高推理性能；整合低光增强、高光削弱、去轮轴镜面反射三个功能，实现对三种单独场景或者任意组合场景进行综合曝光处理。
  超声心脏电生理学与生物力学四川省重点实验室，研究生 超声图像处理算法研究，2020.10~至今
 超声心动图视图分类系统 2022.03~2022.06  利用EfficientNet B7作为骨干网络，配合弱监督的 FGVC-PIM插件进行特征融合与过滤，实现对 6 个超声视图的自动化类别划分，并已在四川省人民医院心血管超声及心功能科进行部署。
 超声心动图质量智能评价系统，2021.12~2022.04  针对在超声心动图扫描过程中存在扫描不规范的问题，利用图像质量评价网络，对图像进行智能打分。
 基于光流循环全对场变换的无监督超声心肌运动追踪，2021.07~至今  搭建用于左心室心肌的*U-Net 3&#43;*网络；并使用无监督的 RAFT 光流网络实现对左心室心肌的运动追踪。
 联合深度学习的通用血流向量成像方法研究，2020.10~2021.03  搭建基于YOLO与U-Net网络的左心室区域检测与室壁分割网络； 实现彩色多普勒超声心动图的血流向量成像方法。
  发表论文
《Ultrasound Vector Flow Mapping in Left Ventricle: A Do It Yourself Study》(EI 收录，第一作者）...</p>
  </div>
  <footer class="entry-footer"><span title='2022-08-21 13:20:39 +0800 CST'>August 21, 2022</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to Resume" href="https://wuyangzz.github.io/2022/resume/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Dicom文件处理
    </h2>
  </header>
  <div class="entry-content">
    <p>使用阈值去掉杂乱的信息 import cv2 import os import pydicom import numpy as np # dicom图像输入路径 inputdir = &#39;/workspace/20210910/Bmodel/inputs&#39; # dicom图像输出路径 outdir = &#39;/workspace/20210910/Bmodel/max_contours_images/&#39; # 获取文件夹下文件列表 files_name_list=os.listdir(inputdir) count=0 # 遍历所有文件 def findMaxcontours(data): _, binaryzation = cv2.threshold(data, 2, 255, cv2.THRESH_BINARY_INV) binaryzation = np.uint8(binaryzation) # 找到所有的轮廓 contours, _ = cv2.findContours( binaryzation, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) area = [] # 找到最大的轮廓 实际应该为第二大轮廓 for k in range(len(contours)): area.append(cv2.contourArea(contours[k])) # max_idx = np.argmax(np.array(area)) max_idx = np.argsort(np.array(area))[-2] # cv2.fillContexPoly(mask[i], contours[max_idx], 0) # 填充最大的轮廓 mask = cv2....</p>
  </div>
  <footer class="entry-footer"><span title='2021-10-09 10:17:39 +0800 CST'>October 9, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to Dicom文件处理" href="https://wuyangzz.github.io/2021/dicom%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>UnSupRAFT运行
    </h2>
  </header>
  <div class="entry-content">
    <p>数据准备 dicom_to_image.py：
import cv2 import os import pydicom # dicom图像输入路径 inputdir = &#39;/workspace/20210910/Bmodel/inputs&#39; # dicom图像输出路径 outdir = &#39;/workspace/UnSupRAFT/datasets/heart/&#39; # 获取文件夹下文件列表 files_name_list=os.listdir(inputdir) count=0 # 遍历所有文件 for file_name in files_name_list: path=os.path.join(inputdir,file_name) ds=pydicom.read_file(path) # 获取该文件的帧数 num_frame=ds.pixel_array.shape[0] # 逐帧保存为PNG无损图像 for i in range(num_frame): # if not os.path.exists(os.path.join(outdir,file_name)): # os.makedirs(os.path.join(outdir,file_name)) if i==0: image1 =ds.pixel_array[i, 70:550, 47:751] else: image2 = ds.pixel_array[i, 70:550, 47:751] cv2.imwrite(os.path.join(outdir, str( count)&#43;&#34;_1.png&#34;), image1, [cv2.IMWRITE_PNG_COMPRESSION, 0]) cv2.imwrite(os.path.join(outdir, str( count)&#43;&#34;_2.png&#34;), image2, [cv2.IMWRITE_PNG_COMPRESSION, 0]) image1=image2 count&#43;=1 设置数据集heart_dataset....</p>
  </div>
  <footer class="entry-footer"><span title='2021-09-29 10:44:43 +0800 CST'>September 29, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to UnSupRAFT运行" href="https://wuyangzz.github.io/2021/unsupraft%E8%BF%90%E8%A1%8C/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>ARflow运作步骤
    </h2>
  </header>
  <div class="entry-content">
    <p>1、安装对应的包 2、修改setup.py文件 c&#43;&#43; 版本 gencode cuda_path
#!/usr/bin/env python3 import os import torch from setuptools import setup, find_packages from torch.utils.cpp_extension import BuildExtension, CUDAExtension cxx_args = [&#39;-std=c&#43;&#43;14&#39;] nvcc_args = [ &#39;-gencode&#39;, &#39;arch=compute_50,code=sm_50&#39;, &#39;-gencode&#39;, &#39;arch=compute_52,code=sm_52&#39;, &#39;-gencode&#39;, &#39;arch=compute_60,code=sm_60&#39;, &#39;-gencode&#39;, &#39;arch=compute_61,code=sm_61&#39;, &#39;-gencode&#39;, &#39;arch=compute_86,code=sm_86&#39;, &#39;-gencode&#39;, &#39;arch=compute_86,code=compute_86&#39;, &#39;-ccbin&#39;, &#39;/usr/bin/gcc&#39; ] setup( name=&#39;correlation_cuda&#39;, ext_modules=[ CUDAExtension(&#39;correlation_cuda&#39;, [ &#39;correlation_cuda.cc&#39;, &#39;correlation_cuda_kernel.cu&#39; ], extra_compile_args={&#39;cxx&#39;: cxx_args, &#39;nvcc&#39;: nvcc_args, &#39;cuda-path&#39;: [&#39;/usr/local/cuda&#39;]}) ], cmdclass={ &#39;build_ext&#39;: BuildExtension }) </p>
  </div>
  <footer class="entry-footer"><span title='2021-09-27 16:19:54 +0800 CST'>September 27, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to ARflow运作步骤" href="https://wuyangzz.github.io/2021/arflow%E8%BF%90%E4%BD%9C%E6%AD%A5%E9%AA%A4/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>基于无监督学习的光流法综述
    </h2>
  </header>
  <div class="entry-content">
    <p>基于U-NetPLusPLUSPLUs和自己监督学习的左心肌运动追踪 摘要 心血管疾病(Cardiovascular diseases ，CVDs)是一种严重威胁人类健康的高发性疾病，其高发病率和死亡率已经严重影响了人类的生存。如何尽早的诊断出心血管疾病尤为重要，在早期通过技术诊断出心肌的生理特性可以有效的获取心室的健康状况，进而尽早的进行干预可以有效的降低心血管疾病的发病率。本文针对左心肌运动的特点，提出一种快速诊断基于像提供的信息，结合Unet3&#43;心室分割和无监督的心肌运动追踪方法获取心肌的运动情况的方法。主要研究的内容有：1、搭建全连接Unet3&#43;网络精确分割左心肌；2、在精确分割左心肌后，根据无监督光流估计方法估计B模式超声心动图连续两帧图像心肌运动情况，得到左心肌位移场信息；3、使用心肌运动模式数据和真实B模式心脏超声数据对心肌运动信息进行量化对比和评估。
心室壁运动追踪应用情况  </p>
  </div>
  <footer class="entry-footer"><span title='2021-09-26 14:08:27 +0800 CST'>September 26, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to 基于无监督学习的光流法综述" href="https://wuyangzz.github.io/2021/%E5%9F%BA%E4%BA%8E%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%85%89%E6%B5%81%E6%B3%95%E7%BB%BC%E8%BF%B0/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Bi Directional Semi Supervised Training of Convolutional Neural Networks for Ultrasound Elastography Displacement Estimation
    </h2>
  </header>
  <div class="entry-content">
    <p>文章阅读 标题Title Bi-Directional Semi-Supervised Training of Convolutional Neural Networks for Ultrasound Elastography Displacement Estimation Ali K. Z. Tehrani, Mostafa Sharifzadeh, Emad Boctor and Hassan Rivaz 超声弹性成像位移估计的卷积神经网络双向半监督训练 审稿文章 发表于TUFFC
摘要Abstract 超声弹性成像的性能在很大程度上取决于位移估计的准确性。最近，卷积神经网络(CNN)在光流估计中显示出良好的性能，并已被用于位移估计 自己实验室最先发表。由于在计算机视觉图像和高频射频超声数据之间存在很大的差距 RFPWC-Net该文章中明确表表明，所以在计算机视觉图像上训练的网络不能直接用于位移估计 (因为超声数据最主要的是有很多的高频数据和噪点) 。许多研究人员试图采用光流CNN，通过应用 迁移学习(自己的心脏模型能不能使用KITTI和fly以及sinetl数据集合上进行先训练，训练以后在进行迁移学习) 来提高CNN的使用性能。然而，实际超声数据中的地面真实位移是未知的，并且仿真数据与真实数据相比表现出域移，并且生成的计算量也很大。为了解决这个问题，已经提出了半监督方法，其中使用真实的超声数据来微调对计算机视觉图像进行预训练的网络。本文采用半监督方法，利用位移场的一阶和二阶导数进行正则化。我们还修改了网络结构以估计向前和向后位移，并提出使用向前和向后应变之间的一致性作为额外的正则化以进一步提高性能。我们用几个实验体模和活体数据验证了我们的方法。我们还表明，由我们提出的方法使用实验体模数据微调的网络在活体数据上表现良好，类似于在活体数据上微调的网络。我们的结果还表明，该方法的性能优于现有的深度学习方法，并且与计算量较大的基于优化的算法相当。
介绍Introduction 超声成像与其他成像手段相比，价格便宜，携带方便，已被越来越多的研究者和临床医生用于诊断和图像引导介入治疗。超声弹性成像(USE)是一种检测组织粘弹性属性的成像技术，已被发现用于不同的应用，包括消融监测[1]、[2]和乳房病变定性[3]。使用方法跟踪组织的运动，大致可分为两组：准静态超声弹性成像和动态超声弹性成像。在动态弹性成像中，声辐射力或内力被用来在组织中产生快速运动[4]。相反，在准静态弹性成像中，组织中的运动是缓慢的，可以通过操作者简单地按下探头(徒手触诊)或使用机械臂来诱导[5]-[8]。
本位主要估计的是使用手触摸组织得到的准静态弹性成像 实际上，弹性成像 (Elastography) 一词最早由 Ophir 等人提出 [a]，因此狭义的弹性成像仅指这种静态力激励下的成像技术 [b]。 其中准静态超声成像技术因具有高分辨率、实时性、不需要额外改进传统超声设备等优点而得到广泛应用。然而,准静态超声弹性成像算法仍然面临着挑战:不正确的匹配点导致弹性成像效果差、实时性要求较高、根据经验设置的窗口系数不能自适应组织等。 [a] Ophir J, Cespedes I, Ponnekanti H, et al. Elastography: a quantitative method for imaging the elasticity of biological tissues[J].Ultrasonic Imaging,1991,13(2):111-134. [b] 罗建文, 白净....</p>
  </div>
  <footer class="entry-footer"><span title='2021-09-22 20:35:49 +0800 CST'>September 22, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to Bi Directional Semi Supervised Training of Convolutional Neural Networks for Ultrasound Elastography Displacement Estimation" href="https://wuyangzz.github.io/2021/bi-directional-semi-supervised-training-of-convolutional-neural-networks-for-ultrasound-elastography-displacement-estimation/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>自监督文献综述
    </h2>
  </header>
  <div class="entry-content">
    <p>综合对比：    paper code Method KITTI 2012 KITTI 2015 Sintel Clean Sintel Final        train test train test(F1-all)   Jason J Y, Harley A W, Derpanis K G. Back to basics: Unsupervised learning of optical flow via brightness constancy and motion smoothness[C]//European Conference on Computer Vision. Springer, Cham, 2016: 3-10. https://github.com/ryersonvisionlab/unsupFlownet BackToBasic 11.3 9.9 – –   Ren Z, Yan J, Ni B, et al....</p>
  </div>
  <footer class="entry-footer"><span title='2021-07-28 15:09:37 +0800 CST'>July 28, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to 自监督文献综述" href="https://wuyangzz.github.io/2021/%E8%87%AA%E7%9B%91%E7%9D%A3%E6%96%87%E7%8C%AE%E7%BB%BC%E8%BF%B0/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>通过类比学习：无监督光流量估计转换的可靠监督
    </h2>
  </header>
  <div class="entry-content">
    <p>CVPR文章  Occlusion Aware Unsupervised Learning of Optical Flow  @misc{wang2018occlusion, title={Occlusion Aware Unsupervised Learning of Optical Flow}, author={Yang Wang and Yi Yang and Zhenheng Yang and Liang Zhao and Peng Wang and Wei Xu}, year={2018}, eprint={1711.05890}, archivePrefix={arXiv}, primaryClass={cs.CV} } 分别求出前向光流和后向光流，通过前向光流进行重建后向光流 $\widetilde{I}_1$ 向后流用于通过前向翘曲产生遮挡贴图$（O）$ photometric loss 光度损失：相当于求两个图片中所有点的相似性。 smoothness loss 正则化平滑：仅基于光度损失的无监督学习对于无纹理的地方是模糊的。减少模糊度最常用的方法就是平滑正则化smoothness loss函数。 文章提高了一种端到端的无监督学习框架，可以训练为标记视频的光流信息。主要参考了FlowNets模型，做出了一定的改进。
可用思路:将FlowNets模型用于我们实验室的PWC-Net模型。其他地方基本可以不用做改变。可以看看后面其他论文改进的部分。
 Learning by Analogy: Reliable Supervision from Transformations for Unsupervised Optical Flow Estimation  @inproceedings{liu2020learning, title = {Learning by Analogy: Reliable Supervision from Transformations for Unsupervised Optical Flow Estimation}, author = {Liu, Liang and Zhang, Jiangning and He, Ruifei and Liu, Yong and Wang, Yabiao and Tai, Ying and Luo, Donghao and Wang, Chengjie and Li, Jilin and Huang, Feiyue}, booktitle = {IEEE Conference on Computer Vision and Pattern Recognition(CVPR)}, year = {2020} } 和上一个网络有一定的差别 以PWC-Net 网络图： 成功在自己笔记本上实现部署模型并且测试代码： 模型部署比较麻烦。需要在cuda9....</p>
  </div>
  <footer class="entry-footer"><span title='2021-07-13 16:19:40 +0800 CST'>July 13, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to 通过类比学习：无监督光流量估计转换的可靠监督" href="https://wuyangzz.github.io/2021/%E9%80%9A%E8%BF%87%E7%B1%BB%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%97%A0%E7%9B%91%E7%9D%A3%E5%85%89%E6%B5%81%E9%87%8F%E4%BC%B0%E8%AE%A1%E8%BD%AC%E6%8D%A2%E7%9A%84%E5%8F%AF%E9%9D%A0%E7%9B%91%E7%9D%A3/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>文章阅读
    </h2>
  </header>
  <div class="entry-content">
    <p>分类 超声模拟心动图 Detailed Evaluation of Five 3D Speckle Tracking Algorithms Using Synthetic Echocardiographic Recordings  作者：Alessandrini, M.; Heyde, B.; Queiros, S. (…) 来源：IEEE Transactions on Medical Imaging, 2016, 35(8), 1915-1926 摘要：3D超声定量心脏畸形和应变需要大量的研究工作。 然而，由于缺乏可靠的验证过程来量化和比较性能，这些技术在临床实践中仍被广泛使用。 在这种情况下，使用全合成序列已成为用于初始计算机评估的既定工具。 然而，现有仿真技术的现实性仍然太局限，无法代表可靠的基准数据。 此外，不同的中心通常会利用内部开发的仿真管道这一事实使得比较存在一定难度。 在原始框架中利用真实的超声记录学习和模拟现实的斑点纹理。模拟的图像显示了典型的伪像，使得在超声挑战中进行运动跟踪。地面真相位移场可用垂直方向通过电子机械模型进行控制。通过对机械和超声参数进行渐进地修改机械和超声算法，以感性地改变3D路径 并可以评估图像属性。 拟议中的管道用于生成包括健康和病理案例在内的8个序列的初始库，可通过我们的项目网页将其免费提供给研究社区。  A Pipeline for the Generation of Realistic 3D Synthetic Echocardiographic Sequences: Methodology and Open-Access Database  作者：Alessandrini, M.; De Craene, M.; Bernard, O. (…) 来源：IEEE Transactions on Medical Imaging, 2015, 34(7), 1436-1451 摘要：使用3D超声对心脏变形和应变进行量化需要大量的研究工作。然而，由于缺乏可靠的验证过程来量化和比较性能，这些技术在临床实践中的广泛使用仍然受到阻碍。在这种情况下，使用完全合成的序列已成为用于初始计算机评估的既定工具。然而，现有仿真技术的现实性仍然太局限，无法代表可靠的基准数据。此外，不同的中心通常利用内部开发的模拟管道这一事实使得进行公平的比较变得困难。在这种情况下，本文介绍了一种用于生成合成3D心脏超声图像序列的新颖流水线。机电建模和超声仿真领域中的最新解决方案在原始框架内进行了组合，该框架利用真实的超声记录来学习和模拟逼真的斑点纹理。模拟图像显示了典型的伪像，这些伪像使超声中的运动跟踪变得困难。地面真实位移场在体素方向可用，并且完全由机电模型控制。通过逐步修改机械和超声参数，可以评估3D应变算法对病理学和图像特性的敏感性。拟议中的管道用于生成包括健康和病理病例在内的8个序列的初始文库，该库可通过我们的项目网页免费提供给研究社区。地面真实位移场在体素方向可用，并且完全由机电模型控制。通过逐步修改机械和超声参数，可以评估3D应变算法对病理学和图像特性的敏感性。拟议中的管道用于生成包括健康和病理病例在内的8个序列的初始文库，该库可通过我们的项目网页免费提供给研究社区。地面实测位移场在体素方向可用，并且完全由机电模型控制。通过逐步修改机械和超声参数，可以评估3D应变算法对病理学和图像特性的敏感性。拟议中的管道用于生成包括健康和病理病例在内的8个序列的初始文库，该库可通过我们的项目网页免费提供给研究社区。  可用于VFM验证</p>
  </div>
  <footer class="entry-footer"><span title='2021-04-28 19:09:00 +0800 CST'>April 28, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to 文章阅读" href="https://wuyangzz.github.io/2021/%E6%96%87%E7%AB%A0%E9%98%85%E8%AF%BB/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Pytorch入门手写数字
    </h2>
  </header>
  <div class="entry-content">
    <p>#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = &#34;./data/&#34;, transform=transform, train = True, download = True) test_data = datasets.MNIST(root=&#34;./data/&#34;, transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本
test_data 的个数：10000个训练样本
train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据...</p>
  </div>
  <footer class="entry-footer"><span title='2021-04-09 13:23:43 +0800 CST'>April 9, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to Pytorch入门手写数字" href="https://wuyangzz.github.io/2021/pytorch%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/"></a>
</article>

<article class="post-entry"> 
  <header class="entry-header">
    <h2>Jupyter中matplotlib中文乱码问题
    </h2>
  </header>
  <div class="entry-content">
    <p>下载字体 首先下载中文字体，链接如下。
字体下载链接 win中下载号以后可以直接安装字体
修改matplotlibrc文件 matplotlibrc文件的位置如下：
D:\Anaconda3\Lib\site-packages\matplotlib\mpl-data （1）删掉 font.family前面的 # 并改为SimHei （2）删掉 font.sans-serif 前面的 #
需要将刚才下载的SimHei添加到其中，如红色方框所示。  保存退出！
把这个路径下的文件都删除（tex.cache和fontlist-.v310josn） c://用户//用户名//.matplotlib
重新启动jupyter </p>
  </div>
  <footer class="entry-footer"><span title='2021-03-26 17:01:43 +0800 CST'>March 26, 2021</span>&nbsp;·&nbsp;wuyangzz</footer>
  <a class="entry-link" aria-label="post link to Jupyter中matplotlib中文乱码问题" href="https://wuyangzz.github.io/2021/jupyter%E4%B8%ADmatplotlib%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://wuyangzz.github.io/posts/page/2/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://wuyangzz.github.io/">wuyangzz</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
