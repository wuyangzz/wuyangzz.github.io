<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Pytorch入门手写数字 | wuyangzz</title>
<meta name="keywords" content="Pytorch">
<meta name="description" content="#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = &#34;./data/&#34;, transform=transform, train = True, download = True) test_data = datasets.MNIST(root=&#34;./data/&#34;, transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本
test_data 的个数：10000个训练样本
train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据">
<meta name="author" content="wuyangzz">
<link rel="canonical" href="https://wuyangzz.github.io/2021/pytorch%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css" integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://wuyangzz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://wuyangzz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://wuyangzz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://wuyangzz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://wuyangzz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Pytorch入门手写数字" />
<meta property="og:description" content="#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = &#34;./data/&#34;, transform=transform, train = True, download = True) test_data = datasets.MNIST(root=&#34;./data/&#34;, transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本
test_data 的个数：10000个训练样本
train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wuyangzz.github.io/2021/pytorch%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-09T13:23:43&#43;08:00" />
<meta property="article:modified_time" content="2021-04-09T13:23:43&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Pytorch入门手写数字"/>
<meta name="twitter:description" content="#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = &#34;./data/&#34;, transform=transform, train = True, download = True) test_data = datasets.MNIST(root=&#34;./data/&#34;, transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本
test_data 的个数：10000个训练样本
train_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://wuyangzz.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Pytorch入门手写数字",
      "item": "https://wuyangzz.github.io/2021/pytorch%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Pytorch入门手写数字",
  "name": "Pytorch入门手写数字",
  "description": "#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = \u0026#34;./data/\u0026#34;, transform=transform, train = True, download = True) test_data = datasets.MNIST(root=\u0026#34;./data/\u0026#34;, transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本\ntest_data 的个数：10000个训练样本\ntrain_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据",
  "keywords": [
    "Pytorch"
  ],
  "articleBody": "#导入需要的包 import numpy as np import torch from torch import nn from PIL import Image import torchvision import matplotlib.pyplot as plt import os from torchvision import datasets, transforms,utils Step1：准备数据。 transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5],std=[0.5])]) train_data = datasets.MNIST(root = \"./data/\", transform=transform, train = True, download = True) test_data = datasets.MNIST(root=\"./data/\", transform = transform, train = False) print(len(train_data)) print(len(test_data)) 60000 10000  train_data 的个数：60000个训练样本\ntest_data 的个数：10000个训练样本\ntrain_loader = torch.utils.data.DataLoader(train_data,batch_size=128, shuffle=True,num_workers=2) test_loader = torch.utils.data.DataLoader(test_data,batch_size=128, shuffle=True,num_workers=2) print(len(train_loader)) print(len(test_loader)) 469 79  加载到dataloader中后，一个dataloader是一个batch的数据\ndata_iter = iter(train_loader) print(next(data_iter)) [tensor([[[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]], [[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]], [[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]], ..., [[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]], [[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]], [[[-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], ..., [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.], [-1., -1., -1., ..., -1., -1., -1.]]]]), tensor([3, 4, 3, 0, 4, 3, 1, 4, 4, 7, 0, 4, 5, 3, 4, 0, 1, 3, 7, 4, 7, 7, 7, 6, 4, 9, 1, 8, 7, 5, 3, 9, 1, 8, 5, 6, 4, 6, 0, 4, 3, 7, 2, 5, 8, 0, 8, 6, 6, 6, 0, 4, 6, 9, 0, 0, 1, 4, 6, 8, 7, 6, 1, 9, 5, 0, 1, 5, 2, 7, 9, 6, 6, 9, 6, 6, 5, 5, 1, 4, 8, 9, 3, 9, 4, 4, 0, 2, 0, 0, 9, 2, 0, 2, 0, 3, 4, 5, 7, 1, 0, 2, 8, 6, 8, 3, 8, 4, 6, 3, 0, 1, 1, 5, 7, 3, 3, 7, 6, 7, 8, 2, 0, 7, 8, 7, 4, 4])]  从二维数组生成一张图片\noneimg,label = train_data[0] oneimg = oneimg.numpy().transpose(1,2,0) std = [0.5] mean = [0.5] oneimg = oneimg * std + mean oneimg.resize(28,28) plt.imshow(oneimg) plt.show() 从三维生成一张黑白图片\noneimg,label = train_data[0] grid = utils.make_grid(oneimg) grid = grid.numpy().transpose(1,2,0) std = [0.5] mean = [0.5] grid = grid * std + mean plt.imshow(grid) plt.show() plt.savefig(\"test.jpg\")  输出一个batch的图片和标签\ndef imshow(img): img = img / 2 + 0.5 # unnormalize npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) plt.show() # torchvision.utils.make_grid 将图片进行拼接 imshow(torchvision.utils.make_grid(iter(train_loader).next()[0])) Step2.网络配置 网络结构是两个卷积层，3个全连接层。\nConv2d参数\n in_channels(int) – 输入信号的通道数目 out_channels(int) – 卷积产生的通道数目 kerner_size(int or tuple) - 卷积核的尺寸 stride(int or tuple, optional) - 卷积步长 padding(int or tuple, optional) - 输入的每一条边补充0的层数  1.定义一个CNN网络\nimport torch.nn.functional as F class CNN(nn.Module): def __init__(self): super(CNN,self).__init__() self.conv1 = nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1) self.pool = nn.MaxPool2d(2,2) self.conv2 = nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1) self.fc1 = nn.Linear(64*7*7,1024)#两个池化，所以是7*7而不是14*14 self.fc2 = nn.Linear(1024,512) self.fc3 = nn.Linear(512,10) # self.dp = nn.Dropout(p=0.5) def forward(self,x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 64 * 7* 7)#将数据平整为一维的  x = F.relu(self.fc1(x)) # x = self.fc3(x) # self.dp(x) x = F.relu(self.fc2(x)) x = self.fc3(x) # x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要 return x net = CNN() 2.定义损失函数和优化函数\nimport torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #也可以选择Adam优化方法 # optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)  Step3.模型训练 train_accs = [] train_loss = [] test_accs = [] # 使用GPU训练模型 device = torch.device(\"cuda:0\") net = net.to(device) for epoch in range(40): running_loss = 0.0 for i,data in enumerate(train_loader,0):#0是下标起始位置默认为0 # data 的格式[[inputs, labels]]  # inputs,labels = data inputs,labels = data[0].to(device), data[1].to(device) #初始为0，清除上个batch的梯度信息 optimizer.zero_grad() #前向+后向+优化  outputs = net(inputs) loss = criterion(outputs,labels) loss.backward() optimizer.step() # loss 的输出，每个一百个batch输出，平均的loss running_loss += loss.item() if i%100 == 99: print('[%d,%5d] loss :%.3f' % (epoch+1,i+1,running_loss/100)) running_loss = 0.0 train_loss.append(loss.item()) # 训练曲线的绘制 一个batch中的准确率 correct = 0 total = 0 _, predicted = torch.max(outputs.data, 1) total = labels.size(0)# labels 的长度 correct = (predicted == labels).sum().item() # 预测正确的数目 train_accs.append(100*correct/total) print('Finished Training') [1, 100] loss :2.294 [1, 200] loss :2.269 [1, 300] loss :2.221 [1, 400] loss :2.088 [2, 100] loss :1.078 [2, 200] loss :0.631 [2, 300] loss :0.483 [2, 400] loss :0.402 [3, 100] loss :0.331 [3, 200] loss :0.297 [3, 300] loss :0.265 [3, 400] loss :0.247 [4, 100] loss :0.225 [4, 200] loss :0.205 [4, 300] loss :0.200 [4, 400] loss :0.176 [5, 100] loss :0.154 [5, 200] loss :0.163 [5, 300] loss :0.151 [5, 400] loss :0.148 [6, 100] loss :0.133 [6, 200] loss :0.119 [6, 300] loss :0.123 [6, 400] loss :0.114 [7, 100] loss :0.110 [7, 200] loss :0.103 [7, 300] loss :0.103 [7, 400] loss :0.097 [8, 100] loss :0.091 [8, 200] loss :0.097 [8, 300] loss :0.092 [8, 400] loss :0.088 [9, 100] loss :0.090 [9, 200] loss :0.086 [9, 300] loss :0.073 [9, 400] loss :0.077 [10, 100] loss :0.079 [10, 200] loss :0.074 [10, 300] loss :0.064 [10, 400] loss :0.078 [11, 100] loss :0.065 [11, 200] loss :0.074 [11, 300] loss :0.071 [11, 400] loss :0.069 [12, 100] loss :0.064 [12, 200] loss :0.059 [12, 300] loss :0.070 [12, 400] loss :0.064 [13, 100] loss :0.055 [13, 200] loss :0.062 [13, 300] loss :0.062 [13, 400] loss :0.063 [14, 100] loss :0.058 [14, 200] loss :0.058 [14, 300] loss :0.064 [14, 400] loss :0.053 [15, 100] loss :0.055 [15, 200] loss :0.054 [15, 300] loss :0.051 [15, 400] loss :0.054 [16, 100] loss :0.052 [16, 200] loss :0.053 [16, 300] loss :0.048 [16, 400] loss :0.052 [17, 100] loss :0.053 [17, 200] loss :0.045 [17, 300] loss :0.051 [17, 400] loss :0.050 [18, 100] loss :0.046 [18, 200] loss :0.042 [18, 300] loss :0.050 [18, 400] loss :0.049 [19, 100] loss :0.048 [19, 200] loss :0.045 [19, 300] loss :0.048 [19, 400] loss :0.043 [20, 100] loss :0.042 [20, 200] loss :0.045 [20, 300] loss :0.040 [20, 400] loss :0.043 [21, 100] loss :0.039 [21, 200] loss :0.042 [21, 300] loss :0.040 [21, 400] loss :0.043 [22, 100] loss :0.039 [22, 200] loss :0.039 [22, 300] loss :0.040 [22, 400] loss :0.039 [23, 100] loss :0.040 [23, 200] loss :0.040 [23, 300] loss :0.035 [23, 400] loss :0.037 [24, 100] loss :0.036 [24, 200] loss :0.038 [24, 300] loss :0.036 [24, 400] loss :0.037 [25, 100] loss :0.038 [25, 200] loss :0.035 [25, 300] loss :0.036 [25, 400] loss :0.036 [26, 100] loss :0.034 [26, 200] loss :0.033 [26, 300] loss :0.036 [26, 400] loss :0.035 [27, 100] loss :0.029 [27, 200] loss :0.031 [27, 300] loss :0.032 [27, 400] loss :0.038 [28, 100] loss :0.028 [28, 200] loss :0.031 [28, 300] loss :0.033 [28, 400] loss :0.032 [29, 100] loss :0.033 [29, 200] loss :0.030 [29, 300] loss :0.026 [29, 400] loss :0.030 [30, 100] loss :0.031 [30, 200] loss :0.030 [30, 300] loss :0.030 [30, 400] loss :0.028 [31, 100] loss :0.032 [31, 200] loss :0.030 [31, 300] loss :0.024 [31, 400] loss :0.030 [32, 100] loss :0.030 [32, 200] loss :0.027 [32, 300] loss :0.028 [32, 400] loss :0.027 [33, 100] loss :0.027 [33, 200] loss :0.028 [33, 300] loss :0.027 [33, 400] loss :0.027 [34, 100] loss :0.025 [34, 200] loss :0.027 [34, 300] loss :0.027 [34, 400] loss :0.027 [35, 100] loss :0.021 [35, 200] loss :0.026 [35, 300] loss :0.026 [35, 400] loss :0.026 [36, 100] loss :0.029 [36, 200] loss :0.024 [36, 300] loss :0.023 [36, 400] loss :0.021 [37, 100] loss :0.023 [37, 200] loss :0.023 [37, 300] loss :0.026 [37, 400] loss :0.023 [38, 100] loss :0.025 [38, 200] loss :0.020 [38, 300] loss :0.025 [38, 400] loss :0.022 [39, 100] loss :0.025 [39, 200] loss :0.022 [39, 300] loss :0.024 [39, 400] loss :0.020 [40, 100] loss :0.022 [40, 200] loss :0.020 [40, 300] loss :0.021 [40, 400] loss :0.023 Finished Training  模型的保存\nPATH = './mnist_net.pth' torch.save(net.state_dict(), PATH) Step4.模型评估 画图\ndef draw_train_process(title,iters,costs,accs,label_cost,lable_acc): plt.title(title, fontsize=24) plt.xlabel(\"iter\", fontsize=20) plt.ylabel(\"acc(\\%)\", fontsize=20) plt.plot(iters, costs,color='red',label=label_cost) plt.plot(iters, accs,color='green',label=lable_acc) plt.legend() plt.grid() plt.show() train_iters = range(len(train_accs)) draw_train_process('training',train_iters,train_loss,train_accs,'training loss','training acc') 检验一个batch的分类情况\ndataiter = iter(test_loader) images, labels = dataiter.next() # print images test_img = utils.make_grid(images) test_img = test_img.numpy().transpose(1,2,0) std = [0.5,0.5,0.5] mean = [0.5,0.5,0.5] test_img = test_img*std+0.5 plt.imshow(test_img) plt.show() print('GroundTruth: ', ' '.join('%d' % labels[j] for j in range(64))) \" / GroundTruth: 0 1 2 1 4 1 2 0 7 2 9 0 2 9 1 5 8 7 5 1 8 3 6 4 7 7 2 3 4 9 5 1 3 7 4 0 2 6 1 4 1 6 0 4 1 9 5 4 1 5 7 7 8 7 5 4 5 8 8 3 1 5 5 9  测试集上面整体的准确率\ncorrect = 0 total = 0 with torch.no_grad():# 进行评测的时候网络不更新梯度 for data in test_loader: images, labels = data outputs = test_net(images) _, predicted = torch.max(outputs.data, 1) total += labels.size(0)# labels 的长度 correct += (predicted == labels).sum().item() # 预测正确的数目 print('Accuracy of the network on the test images: %f%%' % (100. * correct / total)) Accuracy of the network on the test images: 98.860000 %  10个类别的准确率\nclass_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) with torch.no_grad(): for data in test_loader: images, labels = data outputs = test_net(images) _, predicted = torch.max(outputs, 1) c = (predicted == labels) # print(predicted == labels) for i in range(10): label = labels[i] class_correct[label] += c[i].item() class_total[label] += 1 for i in range(10): print('Accuracy of %d: %4f%%' % ( i, 100 * class_correct[i] / class_total[i])) Accuracy of 0 : 100.000000 % Accuracy of 1 : 100.000000 % Accuracy of 2 : 100.000000 % Accuracy of 3 : 100.000000 % Accuracy of 4 : 98.630137 % Accuracy of 5 : 98.765432 % Accuracy of 6 : 97.530864 % Accuracy of 7 : 97.402597 % Accuracy of 8 : 97.058824 % Accuracy of 9 : 98.750000 %  ",
  "wordCount" : "1729",
  "inLanguage": "en",
  "datePublished": "2021-04-09T13:23:43+08:00",
  "dateModified": "2021-04-09T13:23:43+08:00",
  "author":{
    "@type": "Person",
    "name": "wuyangzz"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://wuyangzz.github.io/2021/pytorch%E5%85%A5%E9%97%A8%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "wuyangzz",
    "logo": {
      "@type": "ImageObject",
      "url": "https://wuyangzz.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://wuyangzz.github.io/" accesskey="h" title="wuyangzz (Alt + H)">wuyangzz</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wuyangzz.github.io/posts/" title="博客">
                    <span>博客</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/about/" title="关于我">
                    <span>关于我</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Pytorch入门手写数字
    </h1>
    <div class="post-meta"><span title='2021-04-09 13:23:43 +0800 CST'>April 9, 2021</span>&nbsp;·&nbsp;wuyangzz

</div>
  </header> 
  <div class="post-content"><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#75715e">#导入需要的包</span>
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#f92672">import</span> torch 
<span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
<span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
<span style="color:#f92672">import</span> torchvision
<span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#f92672">as</span> plt
<span style="color:#f92672">import</span> os
<span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> datasets, transforms,utils
</code></pre></div><h1 id="step1准备数据"><strong>Step1：准备数据。</strong><a hidden class="anchor" aria-hidden="true" href="#step1准备数据">#</a></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose([transforms<span style="color:#f92672">.</span>ToTensor(),
                               transforms<span style="color:#f92672">.</span>Normalize(mean<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.5</span>],std<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0.5</span>])])
train_data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>MNIST(root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./data/&#34;</span>,
                            transform<span style="color:#f92672">=</span>transform,
                            train <span style="color:#f92672">=</span> True,
                            download <span style="color:#f92672">=</span> True)

test_data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>MNIST(root<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;./data/&#34;</span>,
                           transform <span style="color:#f92672">=</span> transform,
                           train <span style="color:#f92672">=</span> False)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(len(train_data))
<span style="color:#66d9ef">print</span>(len(test_data))
</code></pre></div><pre><code>60000
10000
</code></pre>
<p>train_data 的个数：60000个训练样本</p>
<p>test_data 的个数：10000个训练样本</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(train_data,batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
                                          shuffle<span style="color:#f92672">=</span>True,num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
test_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(test_data,batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>,
                                          shuffle<span style="color:#f92672">=</span>True,num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(len(train_loader))
<span style="color:#66d9ef">print</span>(len(test_loader))
</code></pre></div><pre><code>469
79
</code></pre>
<p>加载到dataloader中后，一个dataloader是一个batch的数据</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">data_iter <span style="color:#f92672">=</span> iter(train_loader)
<span style="color:#66d9ef">print</span>(next(data_iter))
</code></pre></div><pre><code>[tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]],


        [[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]],


        [[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]],


        ...,


        [[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]],


        [[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]],


        [[[-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          ...,
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.],
          [-1., -1., -1.,  ..., -1., -1., -1.]]]]), tensor([3, 4, 3, 0, 4, 3, 1, 4, 4, 7, 0, 4, 5, 3, 4, 0, 1, 3, 7, 4, 7, 7, 7, 6,
        4, 9, 1, 8, 7, 5, 3, 9, 1, 8, 5, 6, 4, 6, 0, 4, 3, 7, 2, 5, 8, 0, 8, 6,
        6, 6, 0, 4, 6, 9, 0, 0, 1, 4, 6, 8, 7, 6, 1, 9, 5, 0, 1, 5, 2, 7, 9, 6,
        6, 9, 6, 6, 5, 5, 1, 4, 8, 9, 3, 9, 4, 4, 0, 2, 0, 0, 9, 2, 0, 2, 0, 3,
        4, 5, 7, 1, 0, 2, 8, 6, 8, 3, 8, 4, 6, 3, 0, 1, 1, 5, 7, 3, 3, 7, 6, 7,
        8, 2, 0, 7, 8, 7, 4, 4])]
</code></pre>
<p>从二维数组生成一张图片</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">oneimg,label <span style="color:#f92672">=</span> train_data[<span style="color:#ae81ff">0</span>]
oneimg <span style="color:#f92672">=</span> oneimg<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>) 
std <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>]
mean <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>]
oneimg <span style="color:#f92672">=</span> oneimg <span style="color:#f92672">*</span> std <span style="color:#f92672">+</span> mean
oneimg<span style="color:#f92672">.</span>resize(<span style="color:#ae81ff">28</span>,<span style="color:#ae81ff">28</span>)
plt<span style="color:#f92672">.</span>imshow(oneimg)
plt<span style="color:#f92672">.</span>show()
</code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/wuyangzz/blog_image/main/output_10_0.png" alt="output_10_0"  />
</p>
<p>从三维生成一张黑白图片</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">oneimg,label <span style="color:#f92672">=</span> train_data[<span style="color:#ae81ff">0</span>]
grid <span style="color:#f92672">=</span> utils<span style="color:#f92672">.</span>make_grid(oneimg)
grid <span style="color:#f92672">=</span> grid<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>) 
std <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>]
mean <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>]
grid <span style="color:#f92672">=</span> grid <span style="color:#f92672">*</span> std <span style="color:#f92672">+</span> mean
plt<span style="color:#f92672">.</span>imshow(grid)
plt<span style="color:#f92672">.</span>show()
plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#34;test.jpg&#34;</span>)
</code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/wuyangzz/blog_image/main/output_12_0.png" alt="output_12_0"  />
</p>
<pre><code>&lt;Figure size 432x288 with 0 Axes&gt;
</code></pre>
<p>输出一个batch的图片和标签</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">imshow</span>(img):
   img <span style="color:#f92672">=</span> img <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> <span style="color:#ae81ff">0.5</span> <span style="color:#75715e"># unnormalize</span>
   npimg <span style="color:#f92672">=</span> img<span style="color:#f92672">.</span>numpy()
   plt<span style="color:#f92672">.</span>imshow(np<span style="color:#f92672">.</span>transpose(npimg, (<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>)))
   plt<span style="color:#f92672">.</span>show()
<span style="color:#75715e"># torchvision.utils.make_grid 将图片进行拼接</span>
imshow(torchvision<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>make_grid(iter(train_loader)<span style="color:#f92672">.</span>next()[<span style="color:#ae81ff">0</span>]))
</code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/wuyangzz/blog_image/main/output_14_0.png" alt="output_14_0"  />
</p>
<h1 id="step2网络配置"><strong>Step2.网络配置</strong><a hidden class="anchor" aria-hidden="true" href="#step2网络配置">#</a></h1>
<p>网络结构是两个卷积层，3个全连接层。</p>
<p>Conv2d参数</p>
<ul>
<li>in_channels(int) – 输入信号的通道数目</li>
<li>out_channels(int) – 卷积产生的通道数目</li>
<li>kerner_size(int or tuple) - 卷积核的尺寸</li>
<li>stride(int or tuple, optional) - 卷积步长</li>
<li>padding(int or tuple, optional) - 输入的每一条边补充0的层数</li>
</ul>
<p>1.定义一个CNN网络</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#f92672">as</span> F
<span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CNN</span>(nn<span style="color:#f92672">.</span>Module):
    <span style="color:#66d9ef">def</span> __init__(self):
        super(CNN,self)<span style="color:#f92672">.</span>__init__()
        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">32</span>,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
        self<span style="color:#f92672">.</span>pool <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MaxPool2d(<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">2</span>)
        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">32</span>,<span style="color:#ae81ff">64</span>,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
        self<span style="color:#f92672">.</span>fc1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">64</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span><span style="color:#f92672">*</span><span style="color:#ae81ff">7</span>,<span style="color:#ae81ff">1024</span>)<span style="color:#75715e">#两个池化，所以是7*7而不是14*14</span>
        self<span style="color:#f92672">.</span>fc2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">1024</span>,<span style="color:#ae81ff">512</span>)
        self<span style="color:#f92672">.</span>fc3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span>,<span style="color:#ae81ff">10</span>)
<span style="color:#75715e">#         self.dp = nn.Dropout(p=0.5)</span>
    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,x):
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>pool(F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>conv1(x)))
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>pool(F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>conv2(x)))
             
        x <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>view(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">64</span> <span style="color:#f92672">*</span> <span style="color:#ae81ff">7</span><span style="color:#f92672">*</span> <span style="color:#ae81ff">7</span>)<span style="color:#75715e">#将数据平整为一维的 </span>
        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc1(x))
<span style="color:#75715e">#         x = self.fc3(x)</span>
<span style="color:#75715e">#         self.dp(x)</span>
        x <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>relu(self<span style="color:#f92672">.</span>fc2(x))   
        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc3(x)  
<span style="color:#75715e">#         x = F.log_softmax(x,dim=1) NLLLoss()才需要，交叉熵不需要</span>
        <span style="color:#66d9ef">return</span> x
        
net <span style="color:#f92672">=</span> CNN()        
</code></pre></div><p>2.定义损失函数和优化函数</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> torch.optim <span style="color:#f92672">as</span> optim

criterion <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()
optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>SGD(net<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.9</span>)
<span style="color:#75715e">#也可以选择Adam优化方法</span>
<span style="color:#75715e"># optimizer = torch.optim.Adam(net.parameters(),lr=1e-2)   </span>
</code></pre></div><h1 id="step3模型训练"><strong>Step3.模型训练</strong><a hidden class="anchor" aria-hidden="true" href="#step3模型训练">#</a></h1>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_accs <span style="color:#f92672">=</span> []
train_loss <span style="color:#f92672">=</span> []
test_accs <span style="color:#f92672">=</span> []
<span style="color:#75715e"># 使用GPU训练模型</span>
device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda:0&#34;</span>)
net <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>to(device)
<span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">40</span>):
    running_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
    <span style="color:#66d9ef">for</span> i,data <span style="color:#f92672">in</span> enumerate(train_loader,<span style="color:#ae81ff">0</span>):<span style="color:#75715e">#0是下标起始位置默认为0</span>
        <span style="color:#75715e"># data 的格式[[inputs, labels]]       </span>
<span style="color:#75715e">#         inputs,labels = data</span>
        inputs,labels <span style="color:#f92672">=</span> data[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">.</span>to(device), data[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">.</span>to(device)
        <span style="color:#75715e">#初始为0，清除上个batch的梯度信息</span>
        optimizer<span style="color:#f92672">.</span>zero_grad()         
        
        <span style="color:#75715e">#前向+后向+优化     </span>
        outputs <span style="color:#f92672">=</span> net(inputs)
        loss <span style="color:#f92672">=</span> criterion(outputs,labels)
        loss<span style="color:#f92672">.</span>backward()
        optimizer<span style="color:#f92672">.</span>step()
        
        <span style="color:#75715e"># loss 的输出，每个一百个batch输出，平均的loss</span>
        running_loss <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
        <span style="color:#66d9ef">if</span> i<span style="color:#f92672">%</span><span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">99</span>:
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;[</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">,</span><span style="color:#e6db74">%5d</span><span style="color:#e6db74">] loss :</span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>
                 (epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>,i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>,running_loss<span style="color:#f92672">/</span><span style="color:#ae81ff">100</span>))
            running_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
        train_loss<span style="color:#f92672">.</span>append(loss<span style="color:#f92672">.</span>item())
        
        <span style="color:#75715e"># 训练曲线的绘制 一个batch中的准确率</span>
        correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
        _, predicted <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(outputs<span style="color:#f92672">.</span>data, <span style="color:#ae81ff">1</span>)
        total <span style="color:#f92672">=</span> labels<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)<span style="color:#75715e"># labels 的长度</span>
        correct <span style="color:#f92672">=</span> (predicted <span style="color:#f92672">==</span> labels)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item() <span style="color:#75715e"># 预测正确的数目</span>
        train_accs<span style="color:#f92672">.</span>append(<span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>correct<span style="color:#f92672">/</span>total)
        
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Finished Training&#39;</span>)            
</code></pre></div><pre><code>[1,  100] loss :2.294
[1,  200] loss :2.269
[1,  300] loss :2.221
[1,  400] loss :2.088
[2,  100] loss :1.078
[2,  200] loss :0.631
[2,  300] loss :0.483
[2,  400] loss :0.402
[3,  100] loss :0.331
[3,  200] loss :0.297
[3,  300] loss :0.265
[3,  400] loss :0.247
[4,  100] loss :0.225
[4,  200] loss :0.205
[4,  300] loss :0.200
[4,  400] loss :0.176
[5,  100] loss :0.154
[5,  200] loss :0.163
[5,  300] loss :0.151
[5,  400] loss :0.148
[6,  100] loss :0.133
[6,  200] loss :0.119
[6,  300] loss :0.123
[6,  400] loss :0.114
[7,  100] loss :0.110
[7,  200] loss :0.103
[7,  300] loss :0.103
[7,  400] loss :0.097
[8,  100] loss :0.091
[8,  200] loss :0.097
[8,  300] loss :0.092
[8,  400] loss :0.088
[9,  100] loss :0.090
[9,  200] loss :0.086
[9,  300] loss :0.073
[9,  400] loss :0.077
[10,  100] loss :0.079
[10,  200] loss :0.074
[10,  300] loss :0.064
[10,  400] loss :0.078
[11,  100] loss :0.065
[11,  200] loss :0.074
[11,  300] loss :0.071
[11,  400] loss :0.069
[12,  100] loss :0.064
[12,  200] loss :0.059
[12,  300] loss :0.070
[12,  400] loss :0.064
[13,  100] loss :0.055
[13,  200] loss :0.062
[13,  300] loss :0.062
[13,  400] loss :0.063
[14,  100] loss :0.058
[14,  200] loss :0.058
[14,  300] loss :0.064
[14,  400] loss :0.053
[15,  100] loss :0.055
[15,  200] loss :0.054
[15,  300] loss :0.051
[15,  400] loss :0.054
[16,  100] loss :0.052
[16,  200] loss :0.053
[16,  300] loss :0.048
[16,  400] loss :0.052
[17,  100] loss :0.053
[17,  200] loss :0.045
[17,  300] loss :0.051
[17,  400] loss :0.050
[18,  100] loss :0.046
[18,  200] loss :0.042
[18,  300] loss :0.050
[18,  400] loss :0.049
[19,  100] loss :0.048
[19,  200] loss :0.045
[19,  300] loss :0.048
[19,  400] loss :0.043
[20,  100] loss :0.042
[20,  200] loss :0.045
[20,  300] loss :0.040
[20,  400] loss :0.043
[21,  100] loss :0.039
[21,  200] loss :0.042
[21,  300] loss :0.040
[21,  400] loss :0.043
[22,  100] loss :0.039
[22,  200] loss :0.039
[22,  300] loss :0.040
[22,  400] loss :0.039
[23,  100] loss :0.040
[23,  200] loss :0.040
[23,  300] loss :0.035
[23,  400] loss :0.037
[24,  100] loss :0.036
[24,  200] loss :0.038
[24,  300] loss :0.036
[24,  400] loss :0.037
[25,  100] loss :0.038
[25,  200] loss :0.035
[25,  300] loss :0.036
[25,  400] loss :0.036
[26,  100] loss :0.034
[26,  200] loss :0.033
[26,  300] loss :0.036
[26,  400] loss :0.035
[27,  100] loss :0.029
[27,  200] loss :0.031
[27,  300] loss :0.032
[27,  400] loss :0.038
[28,  100] loss :0.028
[28,  200] loss :0.031
[28,  300] loss :0.033
[28,  400] loss :0.032
[29,  100] loss :0.033
[29,  200] loss :0.030
[29,  300] loss :0.026
[29,  400] loss :0.030
[30,  100] loss :0.031
[30,  200] loss :0.030
[30,  300] loss :0.030
[30,  400] loss :0.028
[31,  100] loss :0.032
[31,  200] loss :0.030
[31,  300] loss :0.024
[31,  400] loss :0.030
[32,  100] loss :0.030
[32,  200] loss :0.027
[32,  300] loss :0.028
[32,  400] loss :0.027
[33,  100] loss :0.027
[33,  200] loss :0.028
[33,  300] loss :0.027
[33,  400] loss :0.027
[34,  100] loss :0.025
[34,  200] loss :0.027
[34,  300] loss :0.027
[34,  400] loss :0.027
[35,  100] loss :0.021
[35,  200] loss :0.026
[35,  300] loss :0.026
[35,  400] loss :0.026
[36,  100] loss :0.029
[36,  200] loss :0.024
[36,  300] loss :0.023
[36,  400] loss :0.021
[37,  100] loss :0.023
[37,  200] loss :0.023
[37,  300] loss :0.026
[37,  400] loss :0.023
[38,  100] loss :0.025
[38,  200] loss :0.020
[38,  300] loss :0.025
[38,  400] loss :0.022
[39,  100] loss :0.025
[39,  200] loss :0.022
[39,  300] loss :0.024
[39,  400] loss :0.020
[40,  100] loss :0.022
[40,  200] loss :0.020
[40,  300] loss :0.021
[40,  400] loss :0.023
Finished Training
</code></pre>
<p>模型的保存</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">PATH <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./mnist_net.pth&#39;</span>
torch<span style="color:#f92672">.</span>save(net<span style="color:#f92672">.</span>state_dict(), PATH)
</code></pre></div><h1 id="step4模型评估"><strong>Step4.模型评估</strong><a hidden class="anchor" aria-hidden="true" href="#step4模型评估">#</a></h1>
<p>画图</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">draw_train_process</span>(title,iters,costs,accs,label_cost,lable_acc):
    plt<span style="color:#f92672">.</span>title(title, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">24</span>)
    plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;iter&#34;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
    plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;acc(\%)&#34;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
    plt<span style="color:#f92672">.</span>plot(iters, costs,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>,label<span style="color:#f92672">=</span>label_cost) 
    plt<span style="color:#f92672">.</span>plot(iters, accs,color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;green&#39;</span>,label<span style="color:#f92672">=</span>lable_acc) 
    plt<span style="color:#f92672">.</span>legend()
    plt<span style="color:#f92672">.</span>grid()
    plt<span style="color:#f92672">.</span>show()
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">train_iters <span style="color:#f92672">=</span> range(len(train_accs))
draw_train_process(<span style="color:#e6db74">&#39;training&#39;</span>,train_iters,train_loss,train_accs,<span style="color:#e6db74">&#39;training loss&#39;</span>,<span style="color:#e6db74">&#39;training acc&#39;</span>)
</code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/wuyangzz/blog_image/main/output_28_0.png" alt="output_28_0"  />
</p>
<p>检验一个batch的分类情况</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataiter <span style="color:#f92672">=</span> iter(test_loader)
images, labels <span style="color:#f92672">=</span> dataiter<span style="color:#f92672">.</span>next()

<span style="color:#75715e"># print images</span>
test_img <span style="color:#f92672">=</span> utils<span style="color:#f92672">.</span>make_grid(images)
test_img <span style="color:#f92672">=</span> test_img<span style="color:#f92672">.</span>numpy()<span style="color:#f92672">.</span>transpose(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">2</span>,<span style="color:#ae81ff">0</span>)
std <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">0.5</span>]
mean <span style="color:#f92672">=</span>  [<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">0.5</span>,<span style="color:#ae81ff">0.5</span>]
test_img <span style="color:#f92672">=</span> test_img<span style="color:#f92672">*</span>std<span style="color:#f92672">+</span><span style="color:#ae81ff">0.5</span>
plt<span style="color:#f92672">.</span>imshow(test_img)
plt<span style="color:#f92672">.</span>show()
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;GroundTruth: &#39;</span>, <span style="color:#e6db74">&#39; &#39;</span><span style="color:#f92672">.</span>join(<span style="color:#e6db74">&#39;</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> labels[j] <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">64</span>)))
</code></pre></div><p><img loading="lazy" src="https://raw.githubusercontent.com/wuyangzz/blog_image/main/!%5Bpng%5D%28output_30_0.png%29.png" alt="&lt;img loading=&#34;lazy&#34; src=&#34;output_30_0.png&#34; alt=&#34;png&#34;  /&gt;
"  />
</p>
<pre><code>GroundTruth:  0 1 2 1 4 1 2 0 7 2 9 0 2 9 1 5 8 7 5 1 8 3 6 4 7 7 2 3 4 9 5 1 3 7 4 0 2 6 1 4 1 6 0 4 1 9 5 4 1 5 7 7 8 7 5 4 5 8 8 3 1 5 5 9
</code></pre>
<p>测试集上面整体的准确率</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">correct <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
total <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
<span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():<span style="color:#75715e"># 进行评测的时候网络不更新梯度</span>
    <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> test_loader:
        images, labels <span style="color:#f92672">=</span> data
        outputs <span style="color:#f92672">=</span> test_net(images)
        _, predicted <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(outputs<span style="color:#f92672">.</span>data, <span style="color:#ae81ff">1</span>)
        total <span style="color:#f92672">+=</span> labels<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)<span style="color:#75715e"># labels 的长度</span>
        correct <span style="color:#f92672">+=</span> (predicted <span style="color:#f92672">==</span> labels)<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item() <span style="color:#75715e"># 预测正确的数目</span>
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Accuracy of the network on the  test images: </span><span style="color:#e6db74">%f</span><span style="color:#e6db74"> </span><span style="color:#e6db74">%%</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> (<span style="color:#ae81ff">100.</span> <span style="color:#f92672">*</span> correct <span style="color:#f92672">/</span> total))
</code></pre></div><pre><code>Accuracy of the network on the  test images: 98.860000 %
</code></pre>
<p>10个类别的准确率</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">class_correct <span style="color:#f92672">=</span> list(<span style="color:#ae81ff">0.</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>))
class_total <span style="color:#f92672">=</span> list(<span style="color:#ae81ff">0.</span> <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>))
<span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
    <span style="color:#66d9ef">for</span> data <span style="color:#f92672">in</span> test_loader:
        images, labels <span style="color:#f92672">=</span> data
        outputs <span style="color:#f92672">=</span> test_net(images)
        _, predicted <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(outputs, <span style="color:#ae81ff">1</span>)
        c <span style="color:#f92672">=</span> (predicted <span style="color:#f92672">==</span> labels)
<span style="color:#75715e">#         print(predicted == labels)</span>
        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
            label <span style="color:#f92672">=</span> labels[i]
            class_correct[label] <span style="color:#f92672">+=</span> c[i]<span style="color:#f92672">.</span>item()
            class_total[label] <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>


<span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
    <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;Accuracy of </span><span style="color:#e6db74">%d</span><span style="color:#e6db74"> : </span><span style="color:#e6db74">%4f</span><span style="color:#e6db74"> </span><span style="color:#e6db74">%%</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span> (
        i, <span style="color:#ae81ff">100</span> <span style="color:#f92672">*</span> class_correct[i] <span style="color:#f92672">/</span> class_total[i]))
</code></pre></div><pre><code>Accuracy of 0 : 100.000000 %
Accuracy of 1 : 100.000000 %
Accuracy of 2 : 100.000000 %
Accuracy of 3 : 100.000000 %
Accuracy of 4 : 98.630137 %
Accuracy of 5 : 98.765432 %
Accuracy of 6 : 97.530864 %
Accuracy of 7 : 97.402597 %
Accuracy of 8 : 97.058824 %
Accuracy of 9 : 98.750000 %
</code></pre>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://wuyangzz.github.io/tags/pytorch/">Pytorch</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://wuyangzz.github.io/">wuyangzz</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
