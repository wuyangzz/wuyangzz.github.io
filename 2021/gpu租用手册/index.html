<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>GPU租用手册 | wuyangzz</title>
<meta name="keywords" content="GPU">
<meta name="description" content="一、服务器简介 概述 实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。
 一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。 虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。 如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。 可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。 可以使用web界面如Shipyard等来对docker进行GUI管理 NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。 NGC网站镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。   服务器基本配置    备注 HPC1 HPC2     CPU Intel(R) Xeon(R) CPU E5-2620 2.00GHz Intel(R) Xeon(R) CPU E5-2620 2.00GHz   内存 64 G （8*8G）   硬盘 3T 2T   显卡 技嘉RTX 3090 Turbo*2 技嘉RTX 3090 Turbo*2   IP 172.">
<meta name="author" content="wuyangzz">
<link rel="canonical" href="https://wuyangzz.github.io/2021/gpu%E7%A7%9F%E7%94%A8%E6%89%8B%E5%86%8C/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.abc7c82c3d415a6df50430738d1cbcc4c76fea558bc5a0c830d3babf78167a35.css" integrity="sha256-q8fILD1BWm31BDBzjRy8xMdv6lWLxaDIMNO6v3gWejU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://wuyangzz.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://wuyangzz.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://wuyangzz.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://wuyangzz.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://wuyangzz.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="GPU租用手册" />
<meta property="og:description" content="一、服务器简介 概述 实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。
 一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。 虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。 如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。 可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。 可以使用web界面如Shipyard等来对docker进行GUI管理 NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。 NGC网站镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。   服务器基本配置    备注 HPC1 HPC2     CPU Intel(R) Xeon(R) CPU E5-2620 2.00GHz Intel(R) Xeon(R) CPU E5-2620 2.00GHz   内存 64 G （8*8G）   硬盘 3T 2T   显卡 技嘉RTX 3090 Turbo*2 技嘉RTX 3090 Turbo*2   IP 172." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wuyangzz.github.io/2021/gpu%E7%A7%9F%E7%94%A8%E6%89%8B%E5%86%8C/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-22T14:17:51&#43;08:00" />
<meta property="article:modified_time" content="2021-02-22T14:17:51&#43;08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="GPU租用手册"/>
<meta name="twitter:description" content="一、服务器简介 概述 实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。
 一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。 虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。 如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。 可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。 可以使用web界面如Shipyard等来对docker进行GUI管理 NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。 NGC网站镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。   服务器基本配置    备注 HPC1 HPC2     CPU Intel(R) Xeon(R) CPU E5-2620 2.00GHz Intel(R) Xeon(R) CPU E5-2620 2.00GHz   内存 64 G （8*8G）   硬盘 3T 2T   显卡 技嘉RTX 3090 Turbo*2 技嘉RTX 3090 Turbo*2   IP 172."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://wuyangzz.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "GPU租用手册",
      "item": "https://wuyangzz.github.io/2021/gpu%E7%A7%9F%E7%94%A8%E6%89%8B%E5%86%8C/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "GPU租用手册",
  "name": "GPU租用手册",
  "description": "一、服务器简介 概述 实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。\n 一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。 虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。 如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。 可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。 可以使用web界面如Shipyard等来对docker进行GUI管理 NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。 NGC网站镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。   服务器基本配置    备注 HPC1 HPC2     CPU Intel(R) Xeon(R) CPU E5-2620 2.00GHz Intel(R) Xeon(R) CPU E5-2620 2.00GHz   内存 64 G （8*8G）   硬盘 3T 2T   显卡 技嘉RTX 3090 Turbo*2 技嘉RTX 3090 Turbo*2   IP 172.",
  "keywords": [
    "GPU"
  ],
  "articleBody": "一、服务器简介 概述 实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。\n 一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。 虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。 如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。 可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。 可以使用web界面如Shipyard等来对docker进行GUI管理 NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。 NGC网站镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。   服务器基本配置    备注 HPC1 HPC2     CPU Intel(R) Xeon(R) CPU E5-2620 2.00GHz Intel(R) Xeon(R) CPU E5-2620 2.00GHz   内存 64 G （8*8G）   硬盘 3T 2T   显卡 技嘉RTX 3090 Turbo*2 技嘉RTX 3090 Turbo*2   IP 172.23.253.104 172.23.253.113   Driver Version 460.32.03 460.32.03   CUDA CUDA11.2 CUDA11.2    二、知识准备 2.1 下载Xshell、Xftp，并了解如何使用 2.2 了解什么是Docker、什么是容器 2.3 了解基本的ubuntu使用命令 2.4 了解Jupyter lab使用命令 三、基础环境 3.1 直接提供容器 3.1.1 PyTorch容器 PyTorch是具有Python前端的GPU加速张量计算框架。使用常见的Python库（例如NumPy，SciPy和Cython）可以轻松扩展功能。利用功能性和神经网络层级的基于磁带的系统可以完成自动区分。作为深度学习框架，此功能带来了高度的灵活性和速度，并提供了类似于NumPy的加速功能。本容器基于NGC PyTorch Release 20.12。 此容器映像包含/ opt / pytorch中PyTorch版本的完整源。它是预构建的，并安装在容器映像中的Conda默认环境（/opt/conda/lib/python3.6/site-packages/torch/）中。\n基本软件环境\n Ubuntu 18.04 including Python 3.6 environment Pytorch 1.8.0a0 + 1606899 NVIDIA CUDA 11.1.0 including cuBLAS 11.2.1 NVIDIA cuDNN 8.0.4 APEX MLNX_OFED 5.1 OpenMPI 4.0.5 TensorBoard 1.15.0+nv20.11 Nsight Compute 2020.2.0.18 Nsight Systems 2020.3.4.32 TensorRT 7.2.1 Tensor Core optimized examples Jupyter and JupyterLab: ssh server 其他软件包，用户自行安装。  3.1.2 Tensorflow容器 TensorFlow是用于使用数据流图进行数值计算的开源软件库。图中的节点表示数学运算，而图的边缘表示在它们之间流动的多维数据数组（张量）。这种灵活的体系结构允许您将计算部署到台式机，服务器或移动设备中的一个或多个CPU或GPU上，而无需重写代码。本容器基于NGC TensorFlow Release 20.12。 此容器包括的NVIDIA版本的完整源TensorFlow在/ opt / tensorflow。它是预先构建的，并作为系统Python模块安装。\n其他基本软件环境\n Ubuntu 20.04 Python 3.8 Tensorflow 1.15.4 and 2.3.1 NVIDIA CUDA 11.1.1 including cuBLAS 11.3.0 NVIDIA cuDNN 8.0.5 Horovod 0.20.2 OpenMPI 4.0.5 TensorBoard MLNX_OFED 5.1 TensorRT 7.2.2 DALI 0.28 Nsight Compute 2020.2.1.8 Nsight Systems 2020.3.4.32 XLA-Lite Tensor Core optimized examples JupyterLab 1.2.14 ssh server 其他软件包，用户自行安装。  3.2 NGC官网自定义容器 3.2.1 注册并登录NGC网站 3.2.2 打开NGC网站，其中可以浏览自己所需要的容器 3.2.3 自己根据自己的基础环境 如Tensorflow、Pytorch进行搜索。 进入其中。里面有该容器的参考文档请仔细阅读（参考文档中有基本环境的配置）。只需要将其Pull记住并告诉我。我将做一些基本的配置后即可使用。\n四、收费情况 为了便于计算，将只对GPU使用数量和使用时长进行计费。\n   序号 套餐 GPU数量 计费方式 单价 均价     1 套餐一 单张3090 按小时计费 2元/小时 2元/小时   2 套餐二 单张3090 按天计费 35元/每天 1.45/小时   3 套餐三 单张3090 按周计费 220元/每周 1.31元/小时   4 套餐四 单张3090 按月计费 750元/每月 1.12元/小时   5 套餐五 两张3090 按小时计费 3.6元/小时 3.6元/小时   6 套餐六 两张3090 按天计费 75元/每天 3.125/小时   7 套餐七 两张3090 按周计费 420元/每周 2.5元/小时   8 套餐八 两张3090 按月计费 1400元/每月 2.08元/小时    其他收费\n   序号 项目 费用     1 更换镜像或者端口 30元/次    五、登录方式 5.1 告知基础环境、需要开放的端口、映射文件夹以及用途 我们一般会提供一个使用jupyter的8888端口和一个使用xshell和xftp的22端口。会将容器中的workspace目录映射到Host主机，以免文件丢失。如果有特殊需求，需要提前告知。\n5.2 填写附件1申请服务器资源 5.3 SSH登录方法 用户名： root 初始密码： root ip：给定 端口：给定 登录： ssh root@ -p  登录后立即修改密码：运行 passwd\n5.4 数据上传和下载 使用常见的FTP软件xftp/MobaXterm进行数据的上传和下载 主机名(Host): 给定 端口(Port) : 给定 传输协议(Protocal): SFTP 用户名: root 密码: 你的ssh登录密码\n数据存放建议 所有个人数据建议存放在 /workspace下\n5.5 Jupyter Jupyter Notebook端口：给定 Jupyter Notebook默认密码：root 设置并开启Jupyter Notebook的方法 第一步：在服务器打开终端，输入jupyter notebook --generate-config 生成配置文件 第二步：shell jupyter notebook password  # 按提示，输入密码 第三步：后台运行\nnohup jupyter-lab --ip 0.0.0.0 --port 8888 --allow-root  jupyter.log 2\u00261 \u0026 第五步：在自己的电脑即可登录jupyter notebook: http://给定IP: \n六、连接容器 6.1 使用Xshell新建链接 6.2 链接配置 IP和端口配置（IP和端口都会告知）\n输入账户名和密码（用户名和密码默认为root）\n七、问题咨询 7.1 我能解决的问题 - 容器连接不上（操作无误的情况下） - 需要开放其他额外端口 - 需要几张显卡 - 需要使用时间 - 容器需要重启  7.2 需要自己解决的问题 - Ubuntu怎么使用 - Jupyter怎么使用 - 如何选择适合自己的镜像 - 怎么上传、下载文件 - 镜像里面有什么环境（NGC官网里面有详细的指导文档） - 需要更改容器环境 ",
  "wordCount" : "365",
  "inLanguage": "en",
  "datePublished": "2021-02-22T14:17:51+08:00",
  "dateModified": "2021-02-22T14:17:51+08:00",
  "author":{
    "@type": "Person",
    "name": "wuyangzz"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://wuyangzz.github.io/2021/gpu%E7%A7%9F%E7%94%A8%E6%89%8B%E5%86%8C/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "wuyangzz",
    "logo": {
      "@type": "ImageObject",
      "url": "https://wuyangzz.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://wuyangzz.github.io/" accesskey="h" title="wuyangzz (Alt + H)">wuyangzz</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://wuyangzz.github.io/posts/" title="博客">
                    <span>博客</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
            <li>
                <a href="https://wuyangzz.github.io/about/" title="关于我">
                    <span>关于我</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      GPU租用手册
    </h1>
    <div class="post-meta"><span title='2021-02-22 14:17:51 +0800 CST'>February 22, 2021</span>&nbsp;·&nbsp;wuyangzz

</div>
  </header> 
  <div class="post-content"><h1 id="一服务器简介">一、服务器简介<a hidden class="anchor" aria-hidden="true" href="#一服务器简介">#</a></h1>
<h2 id="概述">概述<a hidden class="anchor" aria-hidden="true" href="#概述">#</a></h2>
<p>实验室利用两台ESC 4000G2 服务器 4张3090显卡搭建GPU服务器。但是因为3090非专业显卡。不支持vGPU功能。如果大家都直接操作宿主主机，直接在宿主主机上配置自己的开发环境将会发生不可避免的冲突。最后经过实际考虑，利用Docker进行合理的系统资源的搭配。使用 Docker 把服务器容器化，每个人都直接登录自己的容器，所有开发都在自己的容器内完成，这样就避免了冲突。并且，Docker 容器的额外开销小得可以忽略不计，所以也不会影响服务器性能。</p>
<ul>
<li>一个docker镜像就可以看作是一个操作系统。在docker上面进行的操作不会影响主机本生的环境。</li>
<li>虚拟容器采用docker方式实现，为了能在docker中可以使用GPU。采用nvidia-docker进行gpu的加载。nvidia-docker 是专门为需要访问显卡资源的容器量身定制的，它对原始的 Docker 命令作了封装，只要使用 nvidia-docker run 命令运行容器，容器就可以访问主机显卡设备（只要主机安装了显卡驱动）。</li>
<li>如果要在docker中使用显卡。现在NVIDIA给出的解决方案中必须使用linux系统。</li>
<li>可以在docker中加载基础的镜像，然后将22端口映射出来。就可以直接使用主机ip加映射的端口来访问和使用docker容器。</li>
<li>可以使用web界面如Shipyard等来对docker进行GUI管理</li>
<li>NVIDIA有官方的Docker目录网站NGC，NGC为AI，机器学习和HPC提供了GPU加速容器的综合中心，这些容器已优化，测试并可以在本地和云中受支持的NVIDIA GPU上运行。此外，它提供了可以轻松集成到现有工作流程中的预训练模型，模型脚本和行业解决方案。</li>
<li><a href="https://ngc.nvidia.com/catalog/containers?orderBy=modifiedDESC&amp;pageNumber=0&amp;query=&amp;quickFilter=containers&amp;filters=">NGC网站</a>镜像中包含很多包，例如TensorFlow，PyTorch，MXNet，NVIDIA TensorRT™，RAPIDS等，并且有各个版本的组合可以下载。更新也非常快。</li>
<li></li>
</ul>
<h2 id="服务器基本配置">服务器基本配置<a hidden class="anchor" aria-hidden="true" href="#服务器基本配置">#</a></h2>
<table>
<thead>
<tr>
<th style="text-align:center">备注</th>
<th style="text-align:center">HPC1</th>
<th style="text-align:center">HPC2</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">CPU</td>
<td style="text-align:center">Intel(R) Xeon(R) CPU E5-2620  2.00GHz</td>
<td style="text-align:center">Intel(R) Xeon(R) CPU E5-2620  2.00GHz</td>
</tr>
<tr>
<td style="text-align:center">内存</td>
<td style="text-align:center">64 G</td>
<td style="text-align:center">（8*8G）</td>
</tr>
<tr>
<td style="text-align:center">硬盘</td>
<td style="text-align:center">3T</td>
<td style="text-align:center">2T</td>
</tr>
<tr>
<td style="text-align:center">显卡</td>
<td style="text-align:center">技嘉RTX 3090 Turbo*2</td>
<td style="text-align:center">技嘉RTX 3090 Turbo*2</td>
</tr>
<tr>
<td style="text-align:center">IP</td>
<td style="text-align:center">172.23.253.104</td>
<td style="text-align:center">172.23.253.113</td>
</tr>
<tr>
<td style="text-align:center">Driver Version</td>
<td style="text-align:center">460.32.03</td>
<td style="text-align:center">460.32.03</td>
</tr>
<tr>
<td style="text-align:center">CUDA</td>
<td style="text-align:center">CUDA11.2</td>
<td style="text-align:center">CUDA11.2</td>
</tr>
</tbody>
</table>
<h1 id="二知识准备">二、知识准备<a hidden class="anchor" aria-hidden="true" href="#二知识准备">#</a></h1>
<h2 id="21-下载xshellxftp并了解如何使用">2.1 下载Xshell、Xftp，并了解如何使用<a hidden class="anchor" aria-hidden="true" href="#21-下载xshellxftp并了解如何使用">#</a></h2>
<h2 id="22-了解什么是docker什么是容器">2.2 了解什么是Docker、什么是容器<a hidden class="anchor" aria-hidden="true" href="#22-了解什么是docker什么是容器">#</a></h2>
<h2 id="23-了解基本的ubuntu使用命令">2.3 了解基本的ubuntu使用命令<a hidden class="anchor" aria-hidden="true" href="#23-了解基本的ubuntu使用命令">#</a></h2>
<h2 id="24-了解jupyter-lab使用命令">2.4 了解Jupyter lab使用命令<a hidden class="anchor" aria-hidden="true" href="#24-了解jupyter-lab使用命令">#</a></h2>
<h1 id="三基础环境">三、基础环境<a hidden class="anchor" aria-hidden="true" href="#三基础环境">#</a></h1>
<h2 id="31-直接提供容器">3.1 直接提供容器<a hidden class="anchor" aria-hidden="true" href="#31-直接提供容器">#</a></h2>
<h3 id="311-pytorch容器">3.1.1 PyTorch容器<a hidden class="anchor" aria-hidden="true" href="#311-pytorch容器">#</a></h3>
<p>PyTorch是具有Python前端的GPU加速张量计算框架。使用常见的Python库（例如NumPy，SciPy和Cython）可以轻松扩展功能。利用功能性和神经网络层级的基于磁带的系统可以完成自动区分。作为深度学习框架，此功能带来了高度的灵活性和速度，并提供了类似于NumPy的加速功能。本容器基于<a href="https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel_20-12.html#rel_20-12">NGC PyTorch Release 20.12</a>。
此容器映像包含/ opt / pytorch中PyTorch版本的完整源。它是预构建的，并安装在容器映像中的Conda默认环境（/opt/conda/lib/python3.6/site-packages/torch/）中。</p>
<p>基本软件环境</p>
<ul>
<li>Ubuntu 18.04 including Python 3.6 environment</li>
<li>Pytorch 1.8.0a0 + 1606899</li>
<li>NVIDIA CUDA 11.1.0 including cuBLAS 11.2.1</li>
<li>NVIDIA cuDNN 8.0.4</li>
<li>APEX</li>
<li>MLNX_OFED 5.1</li>
<li>OpenMPI 4.0.5</li>
<li>TensorBoard 1.15.0+nv20.11</li>
<li>Nsight Compute 2020.2.0.18</li>
<li>Nsight Systems 2020.3.4.32</li>
<li>TensorRT 7.2.1</li>
<li>Tensor Core optimized examples</li>
<li>Jupyter and JupyterLab:</li>
<li>ssh server</li>
<li>其他软件包，用户自行安装。</li>
</ul>
<h3 id="312-tensorflow容器">3.1.2 Tensorflow容器<a hidden class="anchor" aria-hidden="true" href="#312-tensorflow容器">#</a></h3>
<p>TensorFlow是用于使用数据流图进行数值计算的开源软件库。图中的节点表示数学运算，而图的边缘表示在它们之间流动的多维数据数组（张量）。这种灵活的体系结构允许您将计算部署到台式机，服务器或移动设备中的一个或多个CPU或GPU上，而无需重写代码。本容器基于<a href="https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/rel_20-12.html#rel_20-12">NGC TensorFlow Release 20.12</a>。
此容器包括的NVIDIA版本的完整源TensorFlow在/ opt / tensorflow。它是预先构建的，并作为系统Python模块安装。</p>
<p>其他基本软件环境</p>
<ul>
<li>Ubuntu 20.04</li>
<li>Python 3.8</li>
<li>Tensorflow 1.15.4 and 2.3.1</li>
<li>NVIDIA CUDA 11.1.1 including cuBLAS 11.3.0</li>
<li>NVIDIA cuDNN 8.0.5</li>
<li>Horovod 0.20.2</li>
<li>OpenMPI 4.0.5</li>
<li>TensorBoard</li>
<li>MLNX_OFED 5.1</li>
<li>TensorRT 7.2.2</li>
<li>DALI 0.28</li>
<li>Nsight Compute 2020.2.1.8</li>
<li>Nsight Systems 2020.3.4.32</li>
<li>XLA-Lite</li>
<li>Tensor Core optimized examples</li>
<li>JupyterLab 1.2.14</li>
<li>ssh server</li>
<li>其他软件包，用户自行安装。</li>
</ul>
<h2 id="32-ngc官网自定义容器">3.2 NGC官网自定义容器<a hidden class="anchor" aria-hidden="true" href="#32-ngc官网自定义容器">#</a></h2>
<h3 id="321-注册并登录ngc网站httpsngcnvidiacomcatalogcontainersorderbymodifieddescpagenumber0queryquickfiltercontainersfilters">3.2.1 注册并登录<a href="https://ngc.nvidia.com/catalog/containers?orderBy=modifiedDESC&amp;pageNumber=0&amp;query=&amp;quickFilter=containers&amp;filters=">NGC网站</a><a hidden class="anchor" aria-hidden="true" href="#321-注册并登录ngc网站httpsngcnvidiacomcatalogcontainersorderbymodifieddescpagenumber0queryquickfiltercontainersfilters">#</a></h3>
<h3 id="322-打开ngc网站httpsngcnvidiacomcatalogcontainersorderbymodifieddescpagenumber0queryquickfiltercontainersfilters其中可以浏览自己所需要的容器">3.2.2 打开<a href="https://ngc.nvidia.com/catalog/containers?orderBy=modifiedDESC&amp;pageNumber=0&amp;query=&amp;quickFilter=containers&amp;filters=">NGC网站</a>，其中可以浏览自己所需要的容器<a hidden class="anchor" aria-hidden="true" href="#322-打开ngc网站httpsngcnvidiacomcatalogcontainersorderbymodifieddescpagenumber0queryquickfiltercontainersfilters其中可以浏览自己所需要的容器">#</a></h3>
<p><img loading="lazy" src="https://raw.githubusercontent.com/wycyz1/blog_image/main/20201206195516.png" alt="image-20201206195516130"  />
</p>
<h3 id="323-自己根据自己的基础环境-如tensorflowpytorch进行搜索">3.2.3 自己根据自己的基础环境 如Tensorflow、Pytorch进行搜索。<a hidden class="anchor" aria-hidden="true" href="#323-自己根据自己的基础环境-如tensorflowpytorch进行搜索">#</a></h3>
<p>进入其中。里面有该容器的参考文档请仔细阅读（参考文档中有基本环境的配置）。只需要将其Pull记住并告诉我。我将做一些基本的配置后即可使用。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/wycyz1/blog_image/main/20201207181251.png" alt="image-20201207181045933"  />
</p>
<h1 id="四收费情况">四、收费情况<a hidden class="anchor" aria-hidden="true" href="#四收费情况">#</a></h1>
<p>为了便于计算，将只对GPU使用数量和使用时长进行计费。</p>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">套餐</th>
<th style="text-align:center">GPU数量</th>
<th style="text-align:center">计费方式</th>
<th style="text-align:center">单价</th>
<th style="text-align:center">均价</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">套餐一</td>
<td style="text-align:center">单张3090</td>
<td style="text-align:center">按小时计费</td>
<td style="text-align:center">2元/小时</td>
<td style="text-align:center">2元/小时</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">套餐二</td>
<td style="text-align:center">单张3090</td>
<td style="text-align:center">按天计费</td>
<td style="text-align:center">35元/每天</td>
<td style="text-align:center">1.45/小时</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">套餐三</td>
<td style="text-align:center">单张3090</td>
<td style="text-align:center">按周计费</td>
<td style="text-align:center">220元/每周</td>
<td style="text-align:center">1.31元/小时</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">套餐四</td>
<td style="text-align:center">单张3090</td>
<td style="text-align:center">按月计费</td>
<td style="text-align:center">750元/每月</td>
<td style="text-align:center">1.12元/小时</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:center">套餐五</td>
<td style="text-align:center">两张3090</td>
<td style="text-align:center">按小时计费</td>
<td style="text-align:center">3.6元/小时</td>
<td style="text-align:center">3.6元/小时</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:center">套餐六</td>
<td style="text-align:center">两张3090</td>
<td style="text-align:center">按天计费</td>
<td style="text-align:center">75元/每天</td>
<td style="text-align:center">3.125/小时</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:center">套餐七</td>
<td style="text-align:center">两张3090</td>
<td style="text-align:center">按周计费</td>
<td style="text-align:center">420元/每周</td>
<td style="text-align:center">2.5元/小时</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">套餐八</td>
<td style="text-align:center">两张3090</td>
<td style="text-align:center">按月计费</td>
<td style="text-align:center">1400元/每月</td>
<td style="text-align:center">2.08元/小时</td>
</tr>
</tbody>
</table>
<p><strong>其他收费</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center">序号</th>
<th style="text-align:center">项目</th>
<th style="text-align:center">费用</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">更换镜像或者端口</td>
<td style="text-align:center">30元/次</td>
</tr>
</tbody>
</table>
<h1 id="五登录方式">五、登录方式<a hidden class="anchor" aria-hidden="true" href="#五登录方式">#</a></h1>
<h2 id="51-告知基础环境需要开放的端口映射文件夹以及用途">5.1 告知基础环境、需要开放的端口、映射文件夹以及用途<a hidden class="anchor" aria-hidden="true" href="#51-告知基础环境需要开放的端口映射文件夹以及用途">#</a></h2>
<p>我们一般会提供一个使用jupyter的<strong>8888</strong>端口和一个使用xshell和xftp的<strong>22</strong>端口。会将容器中的<strong>workspace</strong>目录映射到Host主机，以免文件丢失。如果有特殊需求，需要提前告知。</p>
<h2 id="52-填写附件1申请服务器资源">5.2 填写附件1申请服务器资源<a hidden class="anchor" aria-hidden="true" href="#52-填写附件1申请服务器资源">#</a></h2>
<h2 id="53-ssh登录方法">5.3 SSH登录方法<a hidden class="anchor" aria-hidden="true" href="#53-ssh登录方法">#</a></h2>
<p>用户名： root
初始密码： root
ip：给定
端口：给定
登录：<code> ssh root@&lt;ip&gt; -p &lt;端口&gt;</code>
登录后立即修改密码：运行 passwd</p>
<h2 id="54-数据上传和下载">5.4 数据上传和下载<a hidden class="anchor" aria-hidden="true" href="#54-数据上传和下载">#</a></h2>
<p>使用常见的FTP软件xftp/MobaXterm进行数据的上传和下载
主机名(Host): 给定
端口(Port) : 给定
传输协议(Protocal): SFTP
用户名: root
密码: 你的ssh登录密码</p>
<p><strong>数据存放建议</strong>
<strong>所有个人数据建议存放在 /workspace下</strong></p>
<h2 id="55-jupyter">5.5 Jupyter<a hidden class="anchor" aria-hidden="true" href="#55-jupyter">#</a></h2>
<p>Jupyter Notebook端口：给定
Jupyter Notebook默认密码：root
设置并开启Jupyter Notebook的方法
第一步：在服务器打开终端，输入<code>jupyter notebook --generate-config</code> 生成配置文件
第二步：<code>shell jupyter notebook password </code>   <em># 按提示，输入密码</em>
第三步：后台运行</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">nohup jupyter-lab --ip 0.0.0.0 --port <span style="color:#ae81ff">8888</span> --allow-root &gt; jupyter.log 2&gt;&amp;<span style="color:#ae81ff">1</span> &amp;  
</code></pre></div><p>第五步：在自己的电脑即可登录jupyter notebook:
http://给定IP: &lt;Jupyter端口&gt;</p>
<h1 id="六连接容器">六、连接容器<a hidden class="anchor" aria-hidden="true" href="#六连接容器">#</a></h1>
<h2 id="61-使用xshell新建链接">6.1 使用Xshell新建链接<a hidden class="anchor" aria-hidden="true" href="#61-使用xshell新建链接">#</a></h2>
<p><img loading="lazy" src="https://raw.githubusercontent.com/wycyz1/blog_image/main/20210102205318.png" alt="image-20210102205318604"  />
</p>
<h2 id="62-链接配置">6.2 链接配置<a hidden class="anchor" aria-hidden="true" href="#62-链接配置">#</a></h2>
<p>IP和端口配置（IP和端口都会告知）</p>
<p><!-- raw HTML omitted --></p>
<p>输入账户名和密码（用户名和密码默认为root）</p>
<p><!-- raw HTML omitted --></p>
<h1 id="七问题咨询">七、问题咨询<a hidden class="anchor" aria-hidden="true" href="#七问题咨询">#</a></h1>
<h2 id="71-我能解决的问题">7.1 我能解决的问题<a hidden class="anchor" aria-hidden="true" href="#71-我能解决的问题">#</a></h2>
<pre><code>- 容器连接不上（操作无误的情况下）
- 需要开放其他额外端口
- 需要几张显卡
- 需要使用时间
- 容器需要重启
</code></pre>
<h2 id="72-需要自己解决的问题">7.2 需要自己解决的问题<a hidden class="anchor" aria-hidden="true" href="#72-需要自己解决的问题">#</a></h2>
<pre><code>- Ubuntu怎么使用
- Jupyter怎么使用
- 如何选择适合自己的镜像
- 怎么上传、下载文件
- 镜像里面有什么环境（NGC官网里面有详细的指导文档）
- 需要更改容器环境</code></pre>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://wuyangzz.github.io/tags/gpu/">GPU</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://wuyangzz.github.io/">wuyangzz</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
